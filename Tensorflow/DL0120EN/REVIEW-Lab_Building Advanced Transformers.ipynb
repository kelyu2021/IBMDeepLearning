{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will: \n",
    "\n",
    "- Implement advanced Transformer models using Keras. \n",
    "\n",
    "- Apply Transformers to real-world sequential data tasks. \n",
    "\n",
    "- Build, train, and evaluate Transformer models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.12.23-py2.py3-none-any.whl.metadata (876 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow) (24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m672.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (391 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.8/391.8 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, pyarrow, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.12.23 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 h5py-3.12.1 keras-3.7.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.1 protobuf-5.29.2 pyarrow-18.1.0 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 werkzeug-3.1.3 wrapt-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m47.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.3 kiwisolver-1.4.8 matplotlib-3.10.0 pillow-11.0.0 pyparsing-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 05:43:12.911882: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-31 05:43:12.916768: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-31 05:43:12.924759: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-31 05:43:12.939494: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735623792.967374      83 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735623792.973721      83 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-31 05:43:13.001268: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape: (2000, 1)\n",
      "data.shape: (2000, 1)\n",
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "print(f'data.shape: {data.shape}')\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "print(f'data.shape: {data.shape}')\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        # print(f'i: {i}, a: {a}')\n",
    "        X.append(a)\n",
    "        # print(f'data[{i+time_step}, 0]: {data[i + time_step, 0]}')\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer):\n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 06:53:52.472564: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "\n",
    "transformer_encoder.summary\n",
    "\n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - loss: 9.5306\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.2458\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1792\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1416\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1275\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1138\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.1169\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1725\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1049\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0846\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1143\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1068\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1022\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.1129\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0654\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0467\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0853\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0455\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0451\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f1fc0ddc410>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 302ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    " \n",
    "\n",
    "# Plot the predictions \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(scaler.inverse_transform(data), label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.show() \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "prev_pub_hash": "28ac4fd81c1d713f83dcd1cdf1d3383ad25ea92873288fe9e978e9a17b314709"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
